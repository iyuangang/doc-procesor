from pathlib import Path
import pandas as pd  # type: ignore
from docx import Document  # type: ignore
from docx.document import Document as DocxDocument
from docx.table import Table as DocxTable
import re
from typing import Dict, Any, Optional, List, Union, Set
import click
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import (
    Progress,
    SpinnerColumn,
    TextColumn,
    BarColumn,
    TaskProgressColumn,
    TimeRemainingColumn,
    TimeElapsedColumn,
)
from rich.syntax import Syntax
from rich.text import Text
from rich.tree import Tree
import textwrap
from functools import lru_cache
import cProfile
import pstats
from io import StringIO
import time
import psutil
import os
from lxml import etree
import gc


# åˆ›å»ºæ§åˆ¶å°å¯¹è±¡
console = Console()


# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
BATCH_NUMBER_PATTERN = re.compile(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶\d]+)æ‰¹")
WHITESPACE_PATTERN = re.compile(r"\s+")
CHINESE_NUMBER_PATTERN = re.compile(r"([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶]+)")

# ä¸­æ–‡æ•°å­—æ˜ å°„è¡¨
CN_NUMS = {
    "é›¶": "0",
    "ä¸€": "1",
    "äºŒ": "2",
    "ä¸‰": "3",
    "å››": "4",
    "äº”": "5",
    "å…­": "6",
    "ä¸ƒ": "7",
    "å…«": "8",
    "ä¹": "9",
    "å": "10",
    "ç™¾": "100",
}


@lru_cache(maxsize=1024)
def cn_to_arabic(cn_num: str) -> str:
    """
    å°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    """
    if cn_num.isdigit():
        return cn_num

    # å¤„ç†ä¸ªä½æ•°
    if len(cn_num) == 1:
        return CN_NUMS.get(cn_num, cn_num)

    # å¤„ç†"ç™¾"å¼€å¤´çš„æ•°å­—
    if "ç™¾" in cn_num:
        parts = cn_num.split("ç™¾")
        hundreds = int(CN_NUMS[parts[0]])
        if not parts[1]:  # æ•´ç™¾
            return str(hundreds * 100)
        # å¤„ç†å¸¦"é›¶"çš„æƒ…å†µ
        if parts[1].startswith("é›¶"):
            ones = int(CN_NUMS[parts[1][-1]])
            return str(hundreds * 100 + ones)
        return str(hundreds * 100 + int(cn_to_arabic(parts[1])))

    # å¤„ç†"å"å¼€å¤´çš„æ•°å­—
    if cn_num.startswith("å"):
        if len(cn_num) == 1:
            return "10"
        return "1" + CN_NUMS[cn_num[1]]

    # å¤„ç†å¸¦åçš„ä¸¤ä½æ•°
    if "å" in cn_num:
        parts = cn_num.split("å")
        tens = CN_NUMS[parts[0]]
        if len(parts) == 1 or not parts[1]:
            return f"{tens}0"
        ones = CN_NUMS[parts[1]]
        return f"{tens}{ones}"

    return CN_NUMS.get(cn_num, cn_num)


@lru_cache(maxsize=1024)
def extract_batch_number(text: str) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå–æ‰¹æ¬¡å·ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    """
    # å…ˆå°è¯•åŒ¹é…å®Œæ•´çš„æ‰¹æ¬¡å·æ ¼å¼
    match = BATCH_NUMBER_PATTERN.search(text)
    if match:
        num = match.group(1)
        # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œç›´æ¥è¿”å›
        if num.isdigit():
            return num

        # è½¬æ¢ä¸­æ–‡æ•°å­—
        try:
            return cn_to_arabic(num)
        except (KeyError, ValueError):
            return None

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‰¹æ¬¡å·æ ¼å¼ï¼Œå°è¯•ç›´æ¥è½¬æ¢çº¯ä¸­æ–‡æ•°å­—
    if any(char in text for char in "ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶"):
        try:
            # æå–è¿ç»­çš„ä¸­æ–‡æ•°å­—
            match = CHINESE_NUMBER_PATTERN.search(text)
            if match:
                return cn_to_arabic(match.group(1))
        except (KeyError, ValueError):
            pass

    return None


@lru_cache(maxsize=1024)
def clean_text(text: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    """
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = WHITESPACE_PATTERN.sub(" ", text.strip())
    # ç»Ÿä¸€å…¨è§’å­—ç¬¦åˆ°åŠè§’
    text = text.replace("ï¼Œ", ",").replace("ï¼›", ";")
    return text


def validate_car_info(car_info: dict[str, Any]) -> tuple[bool, str]:
    """
    éªŒè¯è½¦è¾†ä¿¡æ¯çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§

    Returns:
        (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    required_fields = ["ä¼ä¸šåç§°", "å‹å·"]
    for field in required_fields:
        if field not in car_info or not car_info[field]:
            return False, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"

    if "car_type" not in car_info:
        return False, "ç¼ºå°‘è½¦å‹æ ‡è¯†"

    if car_info["car_type"] not in [1, 2]:
        return False, f"æ— æ•ˆçš„è½¦å‹æ ‡è¯†: {car_info['car_type']}"

    return True, ""


def get_table_type(
    headers: List[str], current_category: Optional[str], current_type: Optional[str]
) -> tuple[str, str]:
    """
    æ ¹æ®è¡¨å¤´åˆ¤æ–­è¡¨æ ¼ç±»å‹
    """
    header_set: Set[str] = set(headers)

    # å¦‚æœæ²¡æœ‰å½“å‰åˆ†ç±»æˆ–ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼
    current_category = current_category or "æœªçŸ¥"
    current_type = current_type or "æœªçŸ¥"

    # å®šä¹‰å„ç±»å‹çš„ç‰¹å¾å­—æ®µ
    type_features: Dict[tuple[str, str], Dict[str, Any]] = {
        ("èŠ‚èƒ½å‹", "ï¼ˆä¸€ï¼‰ä¹˜ç”¨è½¦"): {
            "required": {"æ’é‡(ml)", "ç»¼åˆç‡ƒæ–™æ¶ˆè€—é‡"},
            "optional": {"DCT", "æ¡£ä½æ•°"},
        },
        ("èŠ‚èƒ½å‹", "ï¼ˆäºŒï¼‰è½»å‹å•†ç”¨è½¦"): {
            "required": {"ç‡ƒæ–™ç§ç±»"},
            "condition": lambda h: "CNG" in str(h),
        },
        ("èŠ‚èƒ½å‹", "ï¼ˆä¸‰ï¼‰é‡å‹å•†ç”¨è½¦"): {
            "required": {"ç‡ƒæ–™ç§ç±»"},
            "condition": lambda h: "LNG" in str(h),
        },
        ("æ–°èƒ½æº", "ï¼ˆä¸€ï¼‰æ’ç”µå¼æ··åˆåŠ¨åŠ›ä¹˜ç”¨è½¦"): {
            "required": {"çº¯ç”µåŠ¨ç»­é©¶é‡Œç¨‹", "ç‡ƒæ–™æ¶ˆè€—é‡", "é€šç”¨åç§°"}
        },
        ("æ–°èƒ½æº", "ï¼ˆäºŒï¼‰çº¯ç”µåŠ¨å•†ç”¨è½¦"): {
            "required": {"çº¯ç”µåŠ¨ç»­é©¶é‡Œç¨‹", "åŠ¨åŠ›è“„ç”µæ± æ€»èƒ½é‡"}
        },
        ("æ–°èƒ½æº", "ï¼ˆä¸‰ï¼‰æ’ç”µå¼æ··åˆåŠ¨åŠ›å•†ç”¨è½¦"): {
            "required": {"çº¯ç”µåŠ¨ç»­é©¶é‡Œç¨‹", "ç‡ƒæ–™æ¶ˆè€—é‡"},
            "exclude": {"é€šç”¨åç§°"},
        },
        ("æ–°èƒ½æº", "ï¼ˆå››ï¼‰ç‡ƒæ–™ç”µæ± å•†ç”¨è½¦"): {"required": {"ç‡ƒæ–™ç”µæ± ç³»ç»Ÿé¢å®šåŠŸç‡"}},
    }

    # æ£€æŸ¥æ¯ç§ç±»å‹çš„ç‰¹å¾
    for (category, type_name), features in type_features.items():
        required = features.get("required", set())
        optional = features.get("optional", set())
        condition = features.get("condition", lambda _: True)
        exclude = features.get("exclude", set())

        if (
            required & header_set == required  # å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
            and not (exclude & header_set)  # æ’é™¤å­—æ®µä¸å­˜åœ¨
            and condition(headers)  # æ»¡è¶³é¢å¤–æ¡ä»¶
        ):
            return category, type_name

    return current_category, current_type


def process_car_info(
    car_info: dict[str, Any], batch_number: Optional[str] = None
) -> dict[str, Any]:
    """
    å¤„ç†è½¦è¾†ä¿¡æ¯ï¼Œåˆå¹¶å’Œæ ‡å‡†åŒ–å­—æ®µ

    Args:
        car_info: åŸå§‹è½¦è¾†ä¿¡æ¯å­—å…¸
        batch_number: æ‰¹æ¬¡å·

    Returns:
        å¤„ç†åçš„è½¦è¾†ä¿¡æ¯å­—å…¸
    """
    # æ·»åŠ æ‰¹æ¬¡å·
    if batch_number:
        car_info["batch"] = batch_number

    # åˆå¹¶å‹å·å­—æ®µ
    model_fields = ["äº§å“å‹å·", "è½¦è¾†å‹å·"]
    model_values = []
    for field in model_fields:
        if field in car_info:
            value = car_info.pop(field)
            if value:
                model_values.append(clean_text(value))

    if model_values:
        car_info["å‹å·"] = model_values[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªéç©ºçš„å‹å·

    # æ ‡å‡†åŒ–å­—æ®µåç§°
    field_mapping = {
        "é€šç”¨åç§°": "å“ç‰Œ",
        "å•†æ ‡": "å“ç‰Œ",
    }

    for old_field, new_field in field_mapping.items():
        if old_field in car_info:
            value = car_info.pop(old_field)
            if value and new_field not in car_info:
                car_info[new_field] = clean_text(value)

    # æ¸…ç†å…¶ä»–å­—æ®µçš„æ–‡æœ¬
    for key in car_info:
        if isinstance(car_info[key], str):
            car_info[key] = clean_text(car_info[key])

    return car_info


def extract_doc_content(doc_path: str) -> tuple[list[str], list[dict[str, str]]]:
    """
    æå–æ–‡æ¡£ä¸­é™¤è¡¨æ ¼å¤–çš„å†…å®¹ï¼Œå¹¶åˆ†ç¦»é¢å¤–ä¿¡æ¯
    """
    doc: DocxDocument = Document(doc_path)
    paragraphs: list[str] = []
    extra_info: list[dict[str, str]] = []
    current_section: Optional[str] = None
    batch_found = False
    batch_number = None

    # é¢å¤–ä¿¡æ¯çš„æ ‡è¯†è¯å’Œå¯¹åº”ç±»å‹
    info_types: dict[str, str] = {
        "å‹˜è¯¯": "å‹˜è¯¯",
        "å…³äº": "æ”¿ç­–",
        "ç¬¦åˆ": "è¯´æ˜",
        "æŠ€æœ¯è¦æ±‚": "è¯´æ˜",
        "è‡ªåŠ¨è½¬å…¥": "è¯´æ˜",
        "ç¬¬äºŒéƒ¨åˆ†": "è¯´æ˜",
    }

    # ç”¨äºæ”¶é›†è¿ç»­çš„é¢å¤–ä¿¡æ¯æ–‡æœ¬
    current_extra_info: Optional[dict[str, str]] = None

    def save_current_extra_info() -> None:
        """ä¿å­˜å½“å‰çš„é¢å¤–ä¿¡æ¯"""
        nonlocal current_extra_info
        if current_extra_info:
            # æ¸…ç†å’Œè§„èŒƒåŒ–å†…å®¹
            content = current_extra_info["content"]
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            content = re.sub(r"\s+", " ", content)
            # ç§»é™¤æ¢è¡Œç¬¦
            content = content.replace("\n", " ")
            current_extra_info["content"] = content.strip()

            # æ·»åŠ æ‰¹æ¬¡å·
            if batch_number:
                current_extra_info["batch"] = batch_number

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå¹¶ç›¸åŒç±»å‹å’Œç« èŠ‚çš„ä¿¡æ¯
            for info in extra_info:
                if (
                    info["type"] == current_extra_info["type"]
                    and info["section"] == current_extra_info["section"]
                ):
                    info["content"] = (
                        info["content"] + " " + current_extra_info["content"]
                    )
                    current_extra_info = None
                    return

            extra_info.append(current_extra_info)
            current_extra_info = None

    # éå†æ–‡æ¡£æ®µè½
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            # å¦‚æœé‡åˆ°ç©ºè¡Œï¼Œä¿å­˜å½“å‰çš„é¢å¤–ä¿¡æ¯
            if current_extra_info:
                save_current_extra_info()
            continue

        # æ£€æŸ¥æ‰¹æ¬¡å·
        if not batch_found and "æ‰¹" in text:
            extracted_batch = extract_batch_number(text)
            if extracted_batch:
                batch_number = extracted_batch
                paragraphs.append(text)  # å°†æ‰¹æ¬¡å·ä¿¡æ¯æ”¾åœ¨æœ€å‰é¢
                batch_found = True
                continue

        # è¯†åˆ«ä¸»è¦åˆ†ç±»
        if text.startswith("ä¸€ã€") or text.startswith("äºŒã€"):
            save_current_extra_info()
            current_section = text
            paragraphs.append(text)
        # è¯†åˆ«å­åˆ†ç±»
        elif text.startswith("ï¼ˆ"):
            save_current_extra_info()
            current_section = text
            paragraphs.append(text)
        # è¯†åˆ«é¢å¤–ä¿¡æ¯
        elif any(marker in text for marker in info_types.keys()):
            # å¦‚æœå½“å‰æ–‡æœ¬åŒ…å«æ–°çš„æ ‡è¯†è¯ï¼Œä¿å­˜ä¹‹å‰çš„ä¿¡æ¯å¹¶åˆ›å»ºæ–°çš„
            if current_extra_info:
                save_current_extra_info()

            # åˆ›å»ºæ–°çš„é¢å¤–ä¿¡æ¯
            info_type = next((t for m, t in info_types.items() if m in text), "å…¶ä»–")
            current_extra_info = {
                "section": current_section or "æ–‡æ¡£è¯´æ˜",
                "type": info_type,
                "content": text,
            }
        # å¦‚æœå½“å‰æœ‰æœªå¤„ç†çš„é¢å¤–ä¿¡æ¯ï¼Œå°†æ–‡æœ¬è¿½åŠ åˆ°å†…å®¹ä¸­
        elif current_extra_info is not None:
            current_extra_info["content"] = current_extra_info["content"] + " " + text
        else:
            paragraphs.append(text)

    # ä¿å­˜æœ€åä¸€æ¡æœªå¤„ç†çš„é¢å¤–ä¿¡æ¯
    save_current_extra_info()

    return paragraphs, extra_info


def print_docx_content(doc_path: str) -> None:
    """
    æ‰“å°æ–‡æ¡£å†…å®¹é¢„è§ˆï¼Œæ˜¾ç¤ºæ‰€æœ‰å…ƒç´ çš„è¯¦ç»†ä¿¡æ¯
    """
    try:
        doc: DocxDocument = Document(doc_path)
        console.print(f"\n[bold cyan]æ–‡ä»¶è¯¦ç»†å†…å®¹: {doc_path}[/bold cyan]")

        # åˆ›å»ºä¸€ä¸ªæ ‘å½¢ç»“æ„
        tree = Tree(f"ğŸ“„ {Path(doc_path).name}")

        # æ·»åŠ æ®µè½å†…å®¹
        paragraphs_node = tree.add("[bold]ğŸ“ æ®µè½å†…å®¹[/bold]")
        for i, para in enumerate(doc.paragraphs, 1):
            text = para.text.strip()
            if text:
                # æ˜¾ç¤ºæ®µè½ç¼–å·ã€æ ·å¼å’Œå†…å®¹
                style_name = para.style.name if para.style else "é»˜è®¤æ ·å¼"
                para_node = paragraphs_node.add(
                    f"[blue]æ®µè½ {i}[/blue] ([yellow]{style_name}[/yellow])"
                )
                # å¤„ç†æ®µè½å†…å®¹ï¼Œæ£€æµ‹ç‰¹æ®Šæ ‡è®°
                if "æ‰¹" in text:
                    para_node.add(f"[bold red]æ‰¹æ¬¡ä¿¡æ¯: {text}[/bold red]")
                elif text.startswith(("ä¸€ã€", "äºŒã€")):
                    para_node.add(f"[bold green]ä¸»åˆ†ç±»: {text}[/bold green]")
                elif text.startswith("ï¼ˆ"):
                    para_node.add(f"[bold yellow]å­åˆ†ç±»: {text}[/bold yellow]")
                elif any(
                    marker in text
                    for marker in ["å‹˜è¯¯", "å…³äº", "ç¬¦åˆ", "æŠ€æœ¯è¦æ±‚", "è‡ªåŠ¨è½¬å…¥"]
                ):
                    para_node.add(f"[bold magenta]é¢å¤–ä¿¡æ¯: {text}[/bold magenta]")
                else:
                    para_node.add(Text(textwrap.shorten(text, width=100)))

        # æ·»åŠ è¡¨æ ¼å†…å®¹
        tables_node = tree.add("[bold]ğŸ“Š è¡¨æ ¼å†…å®¹[/bold]")
        for i, table in enumerate(doc.tables, 1):
            if table.rows:
                table_node = tables_node.add(
                    f"[blue]è¡¨æ ¼ {i}[/blue] ({len(table.rows)}è¡Œ x {len(table.rows[0].cells)}åˆ—)"
                )

                # æ˜¾ç¤ºè¡¨å¤´
                headers = [cell.text.strip() for cell in table.rows[0].cells]
                table_node.add("[yellow]è¡¨å¤´:[/yellow] " + " | ".join(headers))

                # æ˜¾ç¤ºæ•°æ®è¡Œé¢„è§ˆ
                data_node = table_node.add("[green]æ•°æ®é¢„è§ˆ:[/green]")
                for row_idx, row in enumerate(table.rows[1:6], 1):  # åªæ˜¾ç¤ºå‰5è¡Œæ•°æ®
                    cells = [cell.text.strip() for cell in row.cells]
                    if any(cells):  # è·³è¿‡ç©ºè¡Œ
                        data_node.add(f"ç¬¬{row_idx}è¡Œ: " + " | ".join(cells))

        # æ˜¾ç¤ºæ–‡æ¡£ç»“æ„æ ‘
        console.print()
        console.print(
            Panel(tree, title="[bold]æ–‡æ¡£ç»“æ„å’Œå†…å®¹[/bold]", border_style="blue")
        )
        console.print()

    except Exception as e:
        console.print(f"[bold red]é¢„è§ˆæ–‡ä»¶ {doc_path} æ—¶å‡ºé”™: {e}[/bold red]")


def display_statistics(
    total_count: int, energy_saving_count: int, new_energy_count: int, output_file: str
) -> None:
    """Display processing statistics in a formatted table."""
    print("\n" + "=" * 50)
    print("å¤„ç†ç»Ÿè®¡æŠ¥å‘Š".center(46))
    print("=" * 50)
    print(f"{'é¡¹ç›®':^20}{'æ•°å€¼':^20}")
    print("-" * 50)
    print(f"{'æ€»è®°å½•æ•°':^20}{total_count:^20,}")
    print(f"{'èŠ‚èƒ½å‹æ±½è½¦':^20}{energy_saving_count:^20,}")
    print(f"{'æ–°èƒ½æºæ±½è½¦':^20}{new_energy_count:^20,}")
    print(f"{'è¾“å‡ºæ–‡ä»¶':^20}{output_file:^20}")
    print("=" * 50 + "\n")


def display_doc_content(
    doc_structure: Union[Dict[str, Any], list[str]],
    extra_info: Optional[Union[str, list[dict[str, str]]]] = None,
) -> None:
    """Display document structure in a tree format with enhanced formatting."""
    # åˆ›å»ºæ–‡æ¡£ç»“æ„æ ‘
    tree = Tree("ğŸ“„ æ–‡æ¡£ç»“æ„")

    def add_to_tree(node: Dict[str, Any], tree_node: Tree) -> None:
        """é€’å½’æ·»åŠ èŠ‚ç‚¹åˆ°æ ‘ä¸­"""
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹é€‰æ‹©æ ·å¼
        style_map = {
            "root": "white",
            "batch": "bold red",
            "section": "bold cyan",
            "subsection": "yellow",
            "subsubsection": "blue",
            "item": "magenta",
            "text": "white",
        }

        # è·å–èŠ‚ç‚¹æ ·å¼
        node_type = node.get("type", "text")
        style = style_map.get(node_type, "white")

        # æ·»åŠ å½“å‰èŠ‚ç‚¹
        name = node.get("name", "")
        if name:
            child = tree_node.add(f"[{style}]{name}[/{style}]")
            # é€’å½’æ·»åŠ å­èŠ‚ç‚¹
            for sub_node in node.get("children", []):
                add_to_tree(sub_node, child)

    # å¤„ç†æ–‡æ¡£ç»“æ„
    if isinstance(doc_structure, dict):
        add_to_tree(doc_structure, tree)
    else:
        # å¦‚æœæ˜¯æ—§æ ¼å¼çš„åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
        root_node = {
            "name": "æ–‡æ¡£å†…å®¹",
            "type": "root",
            "children": [
                {"name": item, "type": "text", "children": []} for item in doc_structure
            ],
        }
        add_to_tree(root_node, tree)

    # æ˜¾ç¤ºæ–‡æ¡£ç»“æ„
    console.print("\n")
    console.print(Panel(tree, border_style="blue"))

    # æ˜¾ç¤ºé¢å¤–ä¿¡æ¯
    if isinstance(extra_info, list) and extra_info:
        # æŒ‰ç±»å‹åˆ†ç»„
        info_by_type: Dict[str, List[dict[str, str]]] = {}
        for info in extra_info:
            info_type = info.get("type", "å…¶ä»–")
            if info_type not in info_by_type:
                info_by_type[info_type] = []
            info_by_type[info_type].append(info)

        # åˆ›å»ºé¢å¤–ä¿¡æ¯æ ‘
        extra_tree = Tree("ğŸ“ é¢å¤–ä¿¡æ¯")
        for info_type, infos in info_by_type.items():
            type_node = extra_tree.add(f"[bold]{info_type}[/bold]")
            for info in infos:
                section = info.get("section", "æœªçŸ¥ç« èŠ‚")
                content = info.get("content", "")
                batch = info.get("batch", "")
                section_node = type_node.add(
                    f"[blue]{section}[/blue]"
                    + (f" [yellow](ç¬¬{batch}æ‰¹)[/yellow]" if batch else "")
                )

                # å¯¹å†…å®¹è¿›è¡Œè‡ªåŠ¨æ¢è¡Œï¼Œç¡®ä¿æ¯è¡Œä¸ä¼šå¤ªé•¿
                wrapped_content = textwrap.fill(
                    content, width=100, break_long_words=False, break_on_hyphens=False
                )
                for line in wrapped_content.split("\n"):
                    section_node.add(line)

        console.print(Panel(extra_tree, border_style="green"))

    console.print()


def display_comparison(new_models: set[str], removed_models: set[str]):
    """
    æ˜¾ç¤ºå‹å·å¯¹æ¯”ç»“æœ
    """
    table = Table(title="å‹å·å¯¹æ¯”", show_header=True, header_style="bold magenta")

    table.add_column("å˜æ›´ç±»å‹", style="dim")
    table.add_column("æ•°é‡", justify="right")
    table.add_column("å‹å·åˆ—è¡¨")

    # æ·»åŠ æ–°å¢å‹å·
    if new_models:
        models_text = "\n".join(sorted(new_models))
        table.add_row("æ–°å¢", str(len(new_models)), models_text)

    # æ·»åŠ ç§»é™¤å‹å·
    if removed_models:
        models_text = "\n".join(sorted(removed_models))
        table.add_row("ç§»é™¤", str(len(removed_models)), models_text)

    if new_models or removed_models:
        console.print()
        console.print(table)
        console.print()
    else:
        console.print("\n[green]æ²¡æœ‰å‹å·å˜æ›´[/green]\n")


@click.group()
def cli():
    """å¤„ç†è½¦è¾†æ•°æ®æ–‡æ¡£çš„å‘½ä»¤è¡Œå·¥å…·"""
    pass


def extract_car_info(doc_path: str, verbose: bool = False) -> List[Dict[str, Any]]:
    """ä»docxæ–‡ä»¶ä¸­æå–è½¦è¾†ä¿¡æ¯"""
    processor = DocProcessor(doc_path)
    return processor.process()


@cli.command()
@click.argument(
    "input_path",
    type=click.Path(exists=True),  # å…è®¸æ–‡ä»¶å’Œç›®å½•
)
@click.option(
    "-o",
    "--output",
    type=click.Path(dir_okay=False),
    default="cars_output.csv",
    help="è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„",
)
@click.option("-v", "--verbose", is_flag=True, help="æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯")
@click.option("--preview", is_flag=True, help="æ˜¾ç¤ºæ–‡æ¡£å†…å®¹é¢„è§ˆ")
@click.option(
    "--compare",
    type=click.Path(exists=True, dir_okay=False),
    help="ä¸æŒ‡å®šçš„CSVæ–‡ä»¶è¿›è¡Œå¯¹æ¯”",
)
def process(
    input_path: str, output: str, verbose: bool, preview: bool, compare: str | None
) -> None:
    """å¤„ç†æŒ‡å®šçš„docxæ–‡ä»¶æˆ–ç›®å½•ä¸‹çš„æ‰€æœ‰docxæ–‡ä»¶"""
    process_files(input_path, output, verbose, preview, compare)


def get_memory_usage() -> str:
    """è·å–å½“å‰è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    return f"{memory_info.rss / 1024 / 1024:.1f}MB"


def process_files(
    input_path: str,
    output: str,
    verbose: bool = False,
    preview: bool = False,
    compare: str | None = None,
) -> None:
    """å¤„ç†æŒ‡å®šçš„docxæ–‡ä»¶æˆ–ç›®å½•ä¸‹çš„æ‰€æœ‰docxæ–‡ä»¶çš„æ ¸å¿ƒé€»è¾‘"""
    NodeType = dict[str, Union[str, list[dict[str, Any]]]]

    # æ ¹æ®è¾“å…¥è·¯å¾„ç±»å‹ç¡®å®šè¦å¤„ç†çš„æ–‡ä»¶
    input_path_obj = Path(input_path)
    if input_path_obj.is_file():
        if input_path_obj.suffix.lower() != ".docx":
            console.print("[bold red]æŒ‡å®šçš„æ–‡ä»¶ä¸æ˜¯docxæ–‡ä»¶")
            return
        doc_files = [input_path_obj]
    else:
        doc_files = list(input_path_obj.glob("*.docx"))

    if not doc_files:
        console.print("[bold red]æœªæ‰¾åˆ°.docxæ–‡ä»¶")
        return

    # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
    if preview:
        for doc_file in doc_files:
            print_docx_content(str(doc_file))

    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    all_cars_data = []
    doc_contents: list[NodeType] = []
    all_extra_info: list[dict[str, str]] = []

    # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        TimeRemainingColumn(),
        TimeElapsedColumn(),
        console=console,
        transient=True,
    ) as progress:
        main_task = progress.add_task("[cyan]å¤„ç†æ–‡ä»¶", total=len(doc_files))

        for doc_file in doc_files:
            try:
                start_time = time.time()
                if verbose:
                    progress.log(f"[bold]å¼€å§‹å¤„ç†æ–‡ä»¶: {doc_file}")
                    progress.log(f"[dim]å½“å‰å†…å­˜ä½¿ç”¨: {get_memory_usage()}[/dim]")

                # æå–æ–‡æ¡£å†…å®¹å’Œé¢å¤–ä¿¡æ¯
                paragraphs, extra_info = extract_doc_content(str(doc_file))
                all_extra_info.extend(extra_info)

                # å¤„ç†è½¦è¾†æ•°æ®
                processor = DocProcessor(str(doc_file))
                cars = processor.process()

                # æ”¶é›†å¤„ç†åçš„æ•°æ®
                if cars:
                    all_cars_data.extend(cars)

                # æ¸…ç†å†…å­˜
                del processor
                gc.collect()

                elapsed = time.time() - start_time
                if verbose:
                    progress.log(
                        f"[bold green]æ–‡ä»¶ {doc_file} å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’[/bold green]"
                    )
                    progress.log(f"[dim]å¤„ç†åå†…å­˜ä½¿ç”¨: {get_memory_usage()}[/dim]")

                progress.advance(main_task)

            except Exception as e:
                progress.log(f"[bold red]å¤„ç†æ–‡ä»¶ {doc_file} æ—¶å‡ºé”™: {e}")

    # åˆ›å»ºæ ¹èŠ‚ç‚¹
    doc_tree = {"name": "æ–‡æ¡£å†…å®¹", "type": "root", "children": doc_contents}

    # æ˜¾ç¤ºç»Ÿè®¡å’Œå†…å®¹
    if all_cars_data:
        # å°†æ”¶é›†çš„æ•°æ®è½¬æ¢ä¸ºDataFrame
        all_cars_df = pd.DataFrame(all_cars_data)

        # è®¾ç½®åˆ—çš„é¡ºåº
        base_columns = [
            "batch",
            "car_type",
            "category",
            "sub_type",
            "åºå·",
            "ä¼ä¸šåç§°",
            "å“ç‰Œ",
            "å‹å·",
            "raw_text",
        ]
        all_columns = list(all_cars_df.columns)

        # å°†å…¶ä»–åˆ—æ·»åŠ åˆ°åŸºç¡€åˆ—åé¢
        existing_columns = [col for col in base_columns if col in all_cars_df.columns]
        other_columns = [col for col in all_columns if col not in base_columns]
        final_columns = existing_columns + other_columns

        # é‡æ–°æ’åˆ—åˆ—å¹¶ä¿å­˜
        all_cars_df = all_cars_df[final_columns]
        all_cars_df.to_csv(output, index=False, encoding="utf-8-sig")

        # æ˜¾ç¤ºç»Ÿè®¡å’Œå†…å®¹
        display_statistics(
            len(all_cars_df),
            len(all_cars_df[all_cars_df["car_type"] == 2]),
            len(all_cars_df[all_cars_df["car_type"] == 1]),
            output,
        )
        display_doc_content(doc_tree, all_extra_info)

        # å¦‚æœéœ€è¦å¯¹æ¯”
        if compare:
            try:
                old_df = pd.read_csv(compare, encoding="utf-8-sig")
                new_models = set(all_cars_df["å‹å·"].unique())
                old_models = set(old_df["å‹å·"].unique())

                display_comparison(new_models - old_models, old_models - new_models)
            except Exception as e:
                console.print(f"[bold red]å¯¹æ¯”æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    else:
        console.print("[bold red]æœªæ‰¾åˆ°ä»»ä½•è½¦è¾†è®°å½•")


@lru_cache(maxsize=32)
def load_document(doc_path: str) -> DocxDocument:
    """ç¼“å­˜åŠ è½½çš„æ–‡æ¡£å¯¹è±¡"""
    return Document(doc_path)


def profile_function(func):
    def wrapper(*args, **kwargs):
        profile = cProfile.Profile()
        try:
            return profile.runcall(func, *args, **kwargs)
        finally:
            s = StringIO()
            stats = pstats.Stats(profile, stream=s).sort_stats("cumulative")
            stats.print_stats(20)  # æ˜¾ç¤ºå‰20ä¸ªæœ€è€—æ—¶çš„å‡½æ•°è°ƒç”¨
            console.print(f"\n[bold cyan]æ€§èƒ½åˆ†ææŠ¥å‘Š:[/bold cyan]\n{s.getvalue()}")

    return wrapper


class DocProcessor:
    """æ–‡æ¡£å¤„ç†å™¨ç±»"""

    def __init__(self, doc_path: str):
        self.doc_path = doc_path
        self.start_time = time.time()
        self.doc: DocxDocument = load_document(doc_path)
        self.current_category: Optional[str] = None
        self.current_type: Optional[str] = None
        self.batch_number: Optional[str] = None
        self._table_cache: Dict[int, List[Dict[str, Any]]] = {}
        self.cars: List[Dict[str, Any]] = []
        self._processing_times: Dict[str, float] = {}
        self._chunk_size = 1000  # åˆ†å—å¤„ç†çš„å¤§å°

    def _extract_table_cells_fast(self, table) -> List[List[str]]:
        """ä½¿ç”¨ä¼˜åŒ–çš„æ–¹å¼æå–è¡¨æ ¼å†…å®¹"""
        rows = []
        for row in table._tbl.tr_lst:  # ç›´æ¥è®¿é—®å†…éƒ¨XMLç»“æ„
            cells = []
            for cell in row.tc_lst:
                # ç›´æ¥è·å–æ–‡æœ¬å†…å®¹
                text = "".join(node.text for node in cell.xpath(".//w:t"))
                cells.append(text.strip())
            if cells:  # åªæ·»åŠ éç©ºè¡Œ
                rows.append(cells)
        return rows

    def _extract_car_info(
        self, table_index: int, batch_number: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """ä»è¡¨æ ¼ä¸­æå–è½¦è¾†ä¿¡æ¯ï¼Œä½¿ç”¨ä¼˜åŒ–çš„å¤„ç†æ–¹å¼"""
        # æ£€æŸ¥ç¼“å­˜
        if table_index in self._table_cache:
            return self._table_cache[table_index]

        start_time = time.time()
        table_cars: List[Dict[str, Any]] = []
        table = self.doc.tables[table_index]

        if not table or not table.rows:
            return table_cars

        # ä½¿ç”¨å¿«é€Ÿæ–¹æ³•æå–æ‰€æœ‰å•å…ƒæ ¼å†…å®¹
        all_rows = self._extract_table_cells_fast(table)
        if not all_rows:
            return table_cars

        # è·å–å¹¶å¤„ç†è¡¨å¤´
        headers = all_rows[0]
        if not headers or not any(headers):
            return table_cars

        # æ ¹æ®è¡¨å¤´åˆ¤æ–­è¡¨æ ¼ç±»å‹
        table_category, table_type = get_table_type(
            headers, self.current_category, self.current_type
        )

        # é¢„å…ˆåˆ›å»ºåŸºç¡€ä¿¡æ¯
        base_info = {
            "category": table_category,
            "sub_type": table_type,
            "car_type": 2 if table_category == "èŠ‚èƒ½å‹" else 1,
            "batch": batch_number,
        }

        total_rows = len(all_rows) - 1
        if total_rows > 100:
            console.print(f"[dim]å¼€å§‹å¤„ç†å¤§è¡¨æ ¼ï¼Œå…± {total_rows} è¡Œ[/dim]")

        # åˆ†å—å¤„ç†æ•°æ®è¡Œ
        for chunk_start in range(1, len(all_rows), self._chunk_size):
            chunk_end = min(chunk_start + self._chunk_size, len(all_rows))
            chunk_rows = all_rows[chunk_start:chunk_end]

            # æ‰¹é‡å¤„ç†å½“å‰å—çš„æ•°æ®è¡Œ
            for cells in chunk_rows:
                if len(cells) != len(headers):  # è·³è¿‡æ ¼å¼ä¸åŒ¹é…çš„è¡Œ
                    continue

                # åˆ›å»ºæ–°çš„å­—å…¸ï¼Œé¿å…å¼•ç”¨åŒä¸€ä¸ªå¯¹è±¡
                car_info = base_info.copy()
                car_info["raw_text"] = " | ".join(cells)

                # ä½¿ç”¨zipä¼˜åŒ–å­—æ®µæ˜ å°„
                car_info.update(
                    {
                        header: clean_text(value)
                        for header, value in zip(headers, cells)
                        if value and header
                    }
                )

                # å¤„ç†è½¦è¾†ä¿¡æ¯
                car_info = process_car_info(car_info, batch_number)

                # éªŒè¯æ•°æ®
                is_valid, _ = validate_car_info(car_info)
                if is_valid:
                    table_cars.append(car_info)

            if total_rows > 100:
                progress = (chunk_end - 1) / total_rows * 100
                console.print(
                    f"[dim]å¤„ç†è¿›åº¦: {progress:.1f}% ({chunk_end-1}/{total_rows})[/dim]"
                )

            # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶
            if len(table_cars) > 5000:
                gc.collect()

        # ç¼“å­˜ç»“æœ
        self._table_cache[table_index] = table_cars

        # è®°å½•å¤„ç†æ—¶é—´
        elapsed = time.time() - start_time
        if total_rows > 100:
            console.print(
                f"[dim]è¡¨æ ¼ {table_index} å¤„ç†äº† {total_rows} è¡Œï¼Œè€—æ—¶: {elapsed:.2f}ç§’[/dim]"
            )

        return table_cars

    def _log_time(self, operation: str) -> None:
        """è®°å½•æ“ä½œè€—æ—¶"""
        current_time = time.time()
        elapsed = current_time - self.start_time
        self._processing_times[operation] = elapsed
        if operation != "init":
            console.print(f"[dim]{operation} è€—æ—¶: {elapsed:.2f}ç§’[/dim]")
        self.start_time = current_time

    @profile_function
    def process(self) -> List[Dict[str, Any]]:
        """å¤„ç†æ–‡æ¡£å¹¶è¿”å›æ‰€æœ‰è½¦è¾†ä¿¡æ¯"""
        self._log_time("init")
        table_count = 0
        row_count = 0

        # éå†æ–‡æ¡£ä¸­çš„æ‰€æœ‰å…ƒç´ 
        for element in self.doc.element.body:
            # å¤„ç†æ®µè½
            if element.tag.endswith("p"):
                text = element.text.strip()
                if not text:
                    continue

                # æå–æ‰¹æ¬¡å·
                if not self.batch_number:
                    self.batch_number = extract_batch_number(text)

                # æ›´æ–°åˆ†ç±»ä¿¡æ¯
                if "ä¸€ã€èŠ‚èƒ½å‹æ±½è½¦" in text:
                    self.current_category = "èŠ‚èƒ½å‹"
                elif "äºŒã€æ–°èƒ½æºæ±½è½¦" in text:
                    self.current_category = "æ–°èƒ½æº"
                elif text.startswith("ï¼ˆ") and "ï¼‰" in text:
                    self.current_type = text.strip()

            # å¤„ç†è¡¨æ ¼
            elif element.tag.endswith("tbl"):
                table_count += 1
                for i, table in enumerate(self.doc.tables):
                    if table._element is element:
                        if table.rows:
                            row_count += len(table.rows)
                        table_cars = self._extract_car_info(i, self.batch_number)
                        self.cars.extend(table_cars)
                        break

        self._log_time("process")
        console.print(f"[dim]å¤„ç†äº† {table_count} ä¸ªè¡¨æ ¼ï¼Œå…± {row_count} è¡Œ[/dim]")
        return self.cars


if __name__ == "__main__":
    cli()
