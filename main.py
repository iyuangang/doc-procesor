from pathlib import Path
import pandas as pd  # type: ignore
from docx import Document  # type: ignore
from docx.document import Document as DocxDocument
from docx.table import Table as DocxTable
import re
from typing import Dict, Any, Optional, List, Union, Set, Tuple
import click
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import (
    Progress,
    SpinnerColumn,
    TextColumn,
    BarColumn,
    TaskProgressColumn,
    TimeRemainingColumn,
    TimeElapsedColumn,
)
from rich.syntax import Syntax
from rich.text import Text
from rich.tree import Tree
import textwrap
from functools import lru_cache, partial
import cProfile
import pstats
from io import StringIO
import time
import psutil
import os
from lxml import etree
import gc
import logging
import multiprocessing as mp
import tempfile
import shutil
import yaml
import logging.config
from datetime import datetime
from dataclasses import dataclass, field


# åˆ›å»ºæ§åˆ¶å°å¯¹è±¡
console = Console()


# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
BATCH_NUMBER_PATTERN = re.compile(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶\d]+)æ‰¹")
WHITESPACE_PATTERN = re.compile(r"\s+")
CHINESE_NUMBER_PATTERN = re.compile(r"([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶]+)")

# ä¸­æ–‡æ•°å­—æ˜ å°„è¡¨
CN_NUMS = {
    "é›¶": "0",
    "ä¸€": "1",
    "äºŒ": "2",
    "ä¸‰": "3",
    "å››": "4",
    "äº”": "5",
    "å…­": "6",
    "ä¸ƒ": "7",
    "å…«": "8",
    "ä¹": "9",
    "å": "10",
    "ç™¾": "100",
}


@lru_cache(maxsize=1024)
def cn_to_arabic(cn_num: str) -> str:
    """
    å°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    """
    if cn_num.isdigit():
        return cn_num

    # å¤„ç†ä¸ªä½æ•°
    if len(cn_num) == 1:
        return CN_NUMS.get(cn_num, cn_num)

    # å¤„ç†"ç™¾"å¼€å¤´çš„æ•°å­—
    if "ç™¾" in cn_num:
        parts = cn_num.split("ç™¾")
        hundreds = int(CN_NUMS[parts[0]])
        if not parts[1]:  # æ•´ç™¾
            return str(hundreds * 100)
        # å¤„ç†å¸¦"é›¶"çš„æƒ…å†µ
        if parts[1].startswith("é›¶"):
            ones = int(CN_NUMS[parts[1][-1]])
            return str(hundreds * 100 + ones)
        return str(hundreds * 100 + int(cn_to_arabic(parts[1])))

    # å¤„ç†"å"å¼€å¤´çš„æ•°å­—
    if cn_num.startswith("å"):
        if len(cn_num) == 1:
            return "10"
        return "1" + CN_NUMS[cn_num[1]]

    # å¤„ç†å¸¦åçš„ä¸¤ä½æ•°
    if "å" in cn_num:
        parts = cn_num.split("å")
        tens = CN_NUMS[parts[0]]
        if len(parts) == 1 or not parts[1]:
            return f"{tens}0"
        ones = CN_NUMS[parts[1]]
        return f"{tens}{ones}"

    return CN_NUMS.get(cn_num, cn_num)


@lru_cache(maxsize=1024)
def extract_batch_number(text: str) -> Optional[str]:
    """
    ä»æ–‡æœ¬ä¸­æå–æ‰¹æ¬¡å·ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    """
    # å…ˆå°è¯•åŒ¹é…å®Œæ•´çš„æ‰¹æ¬¡å·æ ¼å¼
    match = BATCH_NUMBER_PATTERN.search(text)
    if match:
        num = match.group(1)
        # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œç›´æ¥è¿”å›
        if num.isdigit():
            return num

        # è½¬æ¢ä¸­æ–‡æ•°å­—
        try:
            return cn_to_arabic(num)
        except (KeyError, ValueError):
            return None

    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‰¹æ¬¡å·æ ¼å¼ï¼Œå°è¯•ç›´æ¥è½¬æ¢çº¯ä¸­æ–‡æ•°å­—
    if any(char in text for char in "ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶"):
        try:
            # æå–è¿ç»­çš„ä¸­æ–‡æ•°å­—
            match = CHINESE_NUMBER_PATTERN.search(text)
            if match:
                return cn_to_arabic(match.group(1))
        except (KeyError, ValueError):
            pass

    return None


@lru_cache(maxsize=1024)
def clean_text(text: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    """
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = WHITESPACE_PATTERN.sub(" ", text.strip())
    # ç»Ÿä¸€å…¨è§’å­—ç¬¦åˆ°åŠè§’
    text = text.replace("ï¼Œ", ",").replace("ï¼›", ";")
    return text


def validate_car_info(
    car_info: dict[str, Any],
) -> tuple[bool, str, Optional[dict[str, Any]]]:
    """éªŒè¯å¹¶å°è¯•ä¿®å¤è½¦è¾†ä¿¡æ¯"""
    # åŸºæœ¬éªŒè¯
    if not car_info or not any(str(value).strip() for value in car_info.values()):
        return False, "ç©ºè¡Œ", None

    # æ£€æŸ¥æ˜¯å¦ä¸ºåˆè®¡è¡Œ
    if any(
        str(value).strip().startswith(("åˆè®¡", "æ€»è®¡")) for value in car_info.values()
    ):
        return False, "åˆè®¡è¡Œ", None

    # å°è¯•ä¿®å¤æ•°æ®
    fixed_info = car_info.copy()

    # 1. å¤„ç†å˜é€Ÿå™¨ä¿¡æ¯
    if "å‹å¼" in fixed_info and "æ¡£ä½æ•°" in fixed_info:
        fixed_info["å˜é€Ÿå™¨"] = f"{fixed_info.pop('å‹å¼')} {fixed_info.pop('æ¡£ä½æ•°')}"

    # 2. æ ‡å‡†åŒ–æ•°å€¼å­—æ®µ
    numeric_fields = ["æ’é‡(ml)", "æ•´è½¦æ•´å¤‡è´¨é‡(kg)", "ç»¼åˆç‡ƒæ–™æ¶ˆè€—é‡ï¼ˆL/100kmï¼‰"]
    for field in numeric_fields:
        if field in fixed_info:
            value = fixed_info[field]
            if isinstance(value, str):
                # å¤„ç†å¤šä¸ªæ•°å€¼çš„æƒ…å†µï¼ˆå¦‚èŒƒå›´å€¼ï¼‰
                if "/" in value:
                    values = [float(v.strip()) for v in value.split("/") if v.strip()]
                    fixed_info[field] = min(values)  # ä½¿ç”¨æœ€å°å€¼
                else:
                    try:
                        fixed_info[field] = float(value.replace("ï¼Œ", ","))
                    except ValueError:
                        logging.warning(f"æ— æ³•è½¬æ¢æ•°å€¼: {field}={value}")

    # 3. ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
    required_fields = ["car_type", "category", "sub_type"]
    for field in required_fields:
        if field not in fixed_info:
            return False, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}", None

    return True, "", fixed_info


def get_table_type(
    headers: List[str], current_category: Optional[str], current_type: Optional[str]
) -> tuple[str, str]:
    """æ ¹æ®è¡¨å¤´åˆ¤æ–­è¡¨æ ¼ç±»å‹ï¼Œå¢åŠ å¼‚å¸¸å¤„ç†"""
    # æ ‡å‡†åŒ–è¡¨å¤´
    normalized_headers = [h.strip().lower() for h in headers]

    # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = {"åºå·", "ä¼ä¸šåç§°"}
    missing_columns = required_columns - set(normalized_headers)
    if missing_columns:
        raise ValueError(f"è¡¨æ ¼ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")

    # å¤„ç†ç‰¹æ®Šçš„è¡¨å¤´ç»„åˆ
    if "å‹å¼" in normalized_headers and "æ¡£ä½æ•°" in normalized_headers:
        # åˆå¹¶ä¸ºå˜é€Ÿå™¨åˆ—
        idx = normalized_headers.index("å‹å¼")
        normalized_headers[idx] = "å˜é€Ÿå™¨"
        normalized_headers.pop(idx + 1)

    header_set: Set[str] = set(normalized_headers)

    # ä½¿ç”¨æ›´ä¸¥æ ¼çš„ç±»å‹åˆ¤æ–­è§„åˆ™
    type_rules = [
        {
            "category": "èŠ‚èƒ½å‹",
            "type": "ï¼ˆä¸€ï¼‰ä¹˜ç”¨è½¦",
            "required": {"æ’é‡(ml)", "ç»¼åˆç‡ƒæ–™æ¶ˆè€—é‡"},
            "optional": {"å˜é€Ÿå™¨", "dct", "æ¡£ä½æ•°"},
        },
        # ... å…¶ä»–ç±»å‹è§„åˆ™
    ]

    # è®°å½•åŒ¹é…çš„è§„åˆ™
    matched_rules = []
    for rule in type_rules:
        if rule["required"].issubset(header_set):
            if "optional" not in rule or any(
                opt in header_set for opt in rule["optional"]
            ):
                matched_rules.append(rule)

    if len(matched_rules) == 1:
        return matched_rules[0]["category"], matched_rules[0]["type"]
    elif len(matched_rules) > 1:
        # è®°å½•å¤šé‡åŒ¹é…æƒ…å†µ
        logging.warning(f"è¡¨å¤´ {headers} åŒ¹é…å¤šä¸ªç±»å‹: {matched_rules}")
        # ä½¿ç”¨å½“å‰ä¸Šä¸‹æ–‡é€‰æ‹©æœ€å¯èƒ½çš„ç±»å‹
        return current_category or matched_rules[0][
            "category"
        ], current_type or matched_rules[0]["type"]

    # å¦‚æœæ²¡æœ‰åŒ¹é…è§„åˆ™ï¼Œä¿æŒå½“å‰ç±»å‹
    return current_category or "æœªçŸ¥", current_type or "æœªçŸ¥"


def process_car_info(
    car_info: dict[str, Any], batch_number: Optional[str] = None
) -> dict[str, Any]:
    """
    å¤„ç†è½¦è¾†ä¿¡æ¯ï¼Œåˆå¹¶å’Œæ ‡å‡†åŒ–å­—æ®µ

    Args:
        car_info: åŸå§‹è½¦è¾†ä¿¡æ¯å­—å…¸
        batch_number: æ‰¹æ¬¡å·

    Returns:
        å¤„ç†åçš„è½¦è¾†ä¿¡æ¯å­—å…¸
    """
    # æ·»åŠ æ‰¹æ¬¡å·
    if batch_number:
        car_info["batch"] = batch_number

    # åˆå¹¶å‹å·å­—æ®µ
    model_fields = ["äº§å“å‹å·", "è½¦è¾†å‹å·", "å‹å·"]
    model_values = []
    for field in model_fields:
        if field in car_info:
            value = car_info.pop(field) if field != "å‹å·" else car_info.get(field)
            if value and str(value).strip():
                model_values.append(clean_text(str(value)))

    if model_values:
        car_info["å‹å·"] = model_values[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªéç©ºçš„å‹å·

    # æ ‡å‡†åŒ–å­—æ®µåç§°
    field_mapping = {
        "é€šç”¨åç§°": "å“ç‰Œ",
        "å•†æ ‡": "å“ç‰Œ",
        "ç”Ÿäº§ä¼ä¸š": "ä¼ä¸šåç§°",
        "ä¼ä¸š": "ä¼ä¸šåç§°",
    }

    # å¤„ç†å­—æ®µæ˜ å°„
    for old_field, new_field in field_mapping.items():
        if old_field in car_info:
            value = car_info.pop(old_field)
            if value and str(value).strip():
                car_info[new_field] = clean_text(str(value))

    # æ¸…ç†å…¶ä»–å­—æ®µçš„æ–‡æœ¬ï¼Œä½†ä¿ç•™æ‰€æœ‰å€¼
    for key in car_info:
        if isinstance(car_info[key], str):
            car_info[key] = clean_text(car_info[key])

    return car_info


def extract_doc_content(doc_path: str) -> tuple[list[str], list[dict[str, str]]]:
    """
    æå–æ–‡æ¡£ä¸­é™¤è¡¨æ ¼å¤–çš„å†…å®¹ï¼Œå¹¶åˆ†ç¦»é¢å¤–ä¿¡æ¯
    """
    doc: DocxDocument = Document(doc_path)
    paragraphs: list[str] = []
    extra_info: list[dict[str, str]] = []
    current_section: Optional[str] = None
    batch_found = False
    batch_number = None

    # é¢å¤–ä¿¡æ¯çš„æ ‡è¯†è¯å’Œå¯¹åº”ç±»å‹
    info_types: dict[str, str] = {
        "å‹˜è¯¯": "å‹˜è¯¯",
        "å…³äº": "æ”¿ç­–",
        "ç¬¦åˆ": "è¯´æ˜",
        "æŠ€æœ¯è¦æ±‚": "è¯´æ˜",
        "è‡ªåŠ¨è½¬å…¥": "è¯´æ˜",
        "ç¬¬äºŒéƒ¨åˆ†": "è¯´æ˜",
    }

    # ç”¨äºæ”¶é›†è¿ç»­çš„é¢å¤–ä¿¡æ¯æ–‡æœ¬
    current_extra_info: Optional[dict[str, str]] = None

    def save_current_extra_info() -> None:
        """ä¿å­˜å½“å‰çš„é¢å¤–ä¿¡æ¯"""
        nonlocal current_extra_info
        if current_extra_info:
            # æ¸…ç†å’Œè§„èŒƒåŒ–å†…å®¹
            content = current_extra_info["content"]
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            content = re.sub(r"\s+", " ", content)
            # ç§»é™¤æ¢è¡Œç¬¦
            content = content.replace("\n", " ")
            current_extra_info["content"] = content.strip()

            # æ·»åŠ æ‰¹æ¬¡å·
            if batch_number:
                current_extra_info["batch"] = batch_number

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå¹¶ç›¸åŒç±»å‹å’Œç« èŠ‚çš„ä¿¡æ¯
            for info in extra_info:
                if (
                    info["type"] == current_extra_info["type"]
                    and info["section"] == current_extra_info["section"]
                ):
                    info["content"] = (
                        info["content"] + " " + current_extra_info["content"]
                    )
                    current_extra_info = None
                    return

            extra_info.append(current_extra_info)
            current_extra_info = None

    # éå†æ–‡æ¡£æ®µè½
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            # å¦‚æœé‡åˆ°ç©ºè¡Œï¼Œä¿å­˜å½“å‰çš„é¢å¤–ä¿¡æ¯
            if current_extra_info:
                save_current_extra_info()
            continue

        # æ£€æŸ¥æ‰¹æ¬¡å·
        if not batch_found and "æ‰¹" in text:
            extracted_batch = extract_batch_number(text)
            if extracted_batch:
                batch_number = extracted_batch
                paragraphs.append(text)  # å°†æ‰¹æ¬¡å·ä¿¡æ¯æ”¾åœ¨æœ€å‰é¢
                batch_found = True
                continue

        # è¯†åˆ«ä¸»è¦åˆ†ç±»
        if text.startswith("ä¸€ã€") or text.startswith("äºŒã€"):
            save_current_extra_info()
            current_section = text
            paragraphs.append(text)
        # è¯†åˆ«å­åˆ†ç±»
        elif text.startswith("ï¼ˆ"):
            save_current_extra_info()
            current_section = text
            paragraphs.append(text)
        # è¯†åˆ«é¢å¤–ä¿¡æ¯
        elif any(marker in text for marker in info_types.keys()):
            # å¦‚æœå½“å‰æ–‡æœ¬åŒ…å«æ–°çš„æ ‡è¯†è¯ï¼Œä¿å­˜ä¹‹å‰çš„ä¿¡æ¯å¹¶åˆ›å»ºæ–°çš„
            if current_extra_info:
                save_current_extra_info()

            # åˆ›å»ºæ–°çš„é¢å¤–ä¿¡æ¯
            info_type = next((t for m, t in info_types.items() if m in text), "å…¶ä»–")
            current_extra_info = {
                "section": current_section or "æ–‡æ¡£è¯´æ˜",
                "type": info_type,
                "content": text,
            }
        # å¦‚æœå½“å‰æœ‰æœªå¤„ç†çš„é¢å¤–ä¿¡æ¯ï¼Œå°†æ–‡æœ¬è¿½åŠ åˆ°å†…å®¹ä¸­
        elif current_extra_info is not None:
            current_extra_info["content"] = current_extra_info["content"] + " " + text
        else:
            paragraphs.append(text)

    # ä¿å­˜æœ€åä¸€æ¡æœªå¤„ç†çš„é¢å¤–ä¿¡æ¯
    save_current_extra_info()

    return paragraphs, extra_info


def print_docx_content(doc_path: str) -> None:
    """æ‰“å°æ–‡æ¡£å†…å®¹é¢„è§ˆï¼Œæ˜¾ç¤ºæ‰€æœ‰å…ƒç´ çš„è¯¦ç»†ä¿¡æ¯"""
    try:
        doc: DocxDocument = Document(doc_path)
        console.print(
            Panel(
                f"[bold cyan]æ–‡ä»¶è¯¦ç»†å†…å®¹: {doc_path}[/bold cyan]", border_style="cyan"
            )
        )

        # åˆ›å»ºä¸€ä¸ªæ ‘å½¢ç»“æ„
        tree = Tree(f"ğŸ“„ {Path(doc_path).name}", style="bold blue")

        # æ·»åŠ æ®µè½å†…å®¹
        paragraphs_node = tree.add("[bold magenta]ğŸ“ æ®µè½å†…å®¹[/bold magenta]")
        for i, para in enumerate(doc.paragraphs, 1):
            text = para.text.strip()
            if text:
                style_name = para.style.name if para.style else "é»˜è®¤æ ·å¼"
                para_node = paragraphs_node.add(
                    f"[blue]æ®µè½ {i}[/blue] ([yellow]{style_name}[/yellow])"
                )
                if "æ‰¹" in text:
                    para_node.add(f"ğŸ”– [bold red]{text}[/bold red]")
                elif text.startswith(("ä¸€ã€", "äºŒã€")):
                    para_node.add(f"ğŸ“Œ [bold green]{text}[/bold green]")
                elif text.startswith("ï¼ˆ"):
                    para_node.add(f"ğŸ“ [bold yellow]{text}[/bold yellow]")
                elif any(
                    marker in text
                    for marker in ["å‹˜è¯¯", "å…³äº", "ç¬¦åˆ", "æŠ€æœ¯è¦æ±‚", "è‡ªåŠ¨è½¬å…¥"]
                ):
                    para_node.add(f"â„¹ï¸ [bold magenta]{text}[/bold magenta]")
                else:
                    para_node.add(Text(textwrap.shorten(text, width=100)))

        # æ·»åŠ è¡¨æ ¼å†…å®¹
        tables_node = tree.add("[bold cyan]ğŸ“Š è¡¨æ ¼å†…å®¹[/bold cyan]")
        for i, table in enumerate(doc.tables, 1):
            if table.rows:
                table_node = tables_node.add(
                    f"[blue]è¡¨æ ¼ {i}[/blue] ({len(table.rows)}è¡Œ x {len(table.rows[0].cells)}åˆ—)"
                )

                # åˆ›å»ºè¡¨æ ¼é¢„è§ˆ
                preview_table = Table(
                    show_header=True,
                    header_style="bold green",
                    border_style="blue",
                    title=f"è¡¨æ ¼ {i} é¢„è§ˆ",
                    title_style="bold cyan",
                )

                # æ·»åŠ è¡¨å¤´
                headers = [cell.text.strip() for cell in table.rows[0].cells]
                for header in headers:
                    preview_table.add_column(header, overflow="fold")

                # æ·»åŠ æ•°æ®è¡Œé¢„è§ˆ
                for row_idx, row in enumerate(table.rows[1:6], 1):  # åªæ˜¾ç¤ºå‰5è¡Œæ•°æ®
                    cells = [cell.text.strip() for cell in row.cells]
                    if any(cells):  # è·³è¿‡ç©ºè¡Œ
                        preview_table.add_row(*cells)

                table_node.add(preview_table)

        console.print(tree)

    except Exception as e:
        console.print(
            Panel(
                f"[bold red]é¢„è§ˆæ–‡ä»¶ {doc_path} æ—¶å‡ºé”™: {e}[/bold red]",
                border_style="red",
            )
        )


def display_statistics(
    total_count: int, energy_saving_count: int, new_energy_count: int, output_file: str
) -> None:
    """Display processing statistics in a formatted table."""
    # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
    stats_table = Table(
        title="ğŸ“Š å¤„ç†ç»Ÿè®¡æŠ¥å‘Š",
        title_style="bold cyan",
        show_header=True,
        header_style="bold green",
        border_style="blue",
    )

    # æ·»åŠ åˆ—
    stats_table.add_column("é¡¹ç›®", style="cyan")
    stats_table.add_column("æ•°å€¼", justify="right", style="green")
    stats_table.add_column("å æ¯”", justify="right", style="yellow")

    # è®¡ç®—ç™¾åˆ†æ¯”
    energy_saving_percent = (
        energy_saving_count / total_count * 100 if total_count > 0 else 0
    )
    new_energy_percent = new_energy_count / total_count * 100 if total_count > 0 else 0

    # æ·»åŠ è¡Œ
    stats_table.add_row("ğŸ“ æ€»è®°å½•æ•°", f"{total_count:,}", "100%")
    stats_table.add_row(
        "ğŸš— èŠ‚èƒ½å‹æ±½è½¦", f"{energy_saving_count:,}", f"{energy_saving_percent:.1f}%"
    )
    stats_table.add_row(
        "âš¡ æ–°èƒ½æºæ±½è½¦", f"{new_energy_count:,}", f"{new_energy_percent:.1f}%"
    )
    stats_table.add_row("ğŸ’¾ è¾“å‡ºæ–‡ä»¶", output_file, "")

    # æ˜¾ç¤ºè¡¨æ ¼
    console.print()
    console.print(stats_table)
    console.print()


@dataclass
class DocumentNode:
    """æ–‡æ¡£èŠ‚ç‚¹ç±»ï¼Œç”¨äºæ„å»ºæ–‡æ¡£æ ‘ç»“æ„"""

    title: str
    level: int
    node_type: str  # 'section', 'subsection', 'table', 'text', 'note', 'correction'
    content: Optional[str] = None
    batch_number: Optional[str] = None
    children: List["DocumentNode"] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


class DocumentStructure:
    """æ–‡æ¡£ç»“æ„ç±»ï¼Œç”¨äºæ„å»ºå’Œç®¡ç†æ–‡æ¡£çš„å±‚çº§ç»“æ„"""

    def __init__(self):
        self.root = DocumentNode("æ–‡æ¡£ç»“æ„", 0, "root")
        self.current_section: Optional[DocumentNode] = None
        self.current_subsection: Optional[DocumentNode] = None
        self.batch_number: Optional[str] = None

    def add_node(
        self,
        title: str,
        node_type: str,
        content: Optional[str] = None,
        level: Optional[int] = None,
        metadata: Optional[Dict[str, Any]] = None,
        parent_node: Optional[DocumentNode] = None,
    ) -> DocumentNode:
        """æ·»åŠ æ–°èŠ‚ç‚¹åˆ°æ–‡æ¡£æ ‘"""
        if level is None:
            if node_type == "section":
                level = 1
            elif node_type == "subsection":
                level = 2
            elif node_type == "numbered_section":
                level = 3
            elif node_type == "numbered_subsection":
                level = 4
            else:
                level = 5

        node = DocumentNode(
            title=title,
            level=level,
            node_type=node_type,
            content=content,
            batch_number=self.batch_number,
            metadata=metadata or {},
        )

        # å¦‚æœæŒ‡å®šäº†çˆ¶èŠ‚ç‚¹ï¼Œç›´æ¥æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
        if parent_node:
            parent_node.children.append(node)
            return node

        # å¦åˆ™ä½¿ç”¨é»˜è®¤çš„å±‚çº§é€»è¾‘
        if level == 1:
            self.root.children.append(node)
        elif level == 2:
            if self.current_section:
                self.current_section.children.append(node)
            else:
                self.root.children.append(node)
        else:
            if self.current_subsection:
                self.current_subsection.children.append(node)
            elif self.current_section:
                self.current_section.children.append(node)
            else:
                self.root.children.append(node)

        return node

    def set_batch_number(self, batch_number: str):
        """è®¾ç½®æ‰¹æ¬¡å·"""
        self.batch_number = batch_number

    def to_dict(self) -> Dict[str, Any]:
        """å°†æ–‡æ¡£ç»“æ„è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""

        def node_to_dict(node: DocumentNode) -> Dict[str, Any]:
            return {
                "title": node.title,
                "type": node.node_type,
                "level": node.level,
                "content": node.content,
                "batch_number": node.batch_number,
                "metadata": node.metadata,
                "children": [node_to_dict(child) for child in node.children],
            }

        return node_to_dict(self.root)


def display_doc_content(doc_structure: DocumentStructure) -> None:
    """ä½¿ç”¨æ ‘å½¢ç»“æ„æ˜¾ç¤ºæ–‡æ¡£å†…å®¹"""

    def get_node_style(node: DocumentNode) -> Tuple[str, str]:
        """è·å–èŠ‚ç‚¹çš„æ ·å¼å’Œå›¾æ ‡"""
        styles = {
            "root": ("bold blue", "ğŸ“‘"),
            "section": ("bold cyan", "ğŸ“Œ"),
            "subsection": ("bold yellow", "ğŸ“"),
            "numbered_section": ("bold green", "ğŸ”¢"),
            "numbered_subsection": ("bold magenta", "ğŸ“"),
            "table": ("bold blue", "ğŸ“Š"),
            "text": ("white", "ğŸ“"),
            "note": ("bold magenta", "â„¹ï¸"),
            "correction": ("bold red", "âš ï¸"),
        }
        return styles.get(node.node_type, ("white", "â€¢"))

    def add_node_to_tree(tree: Tree, node: DocumentNode) -> None:
        """é€’å½’æ·»åŠ èŠ‚ç‚¹åˆ°æ ‘ä¸­"""
        style, icon = get_node_style(node)

        # æ„å»ºèŠ‚ç‚¹æ ‡é¢˜
        title = f"{icon} {node.title}"
        if node.batch_number and node.level <= 2:
            title += f" [dim](ç¬¬{node.batch_number}æ‰¹)[/dim]"

        # åˆ›å»ºèŠ‚ç‚¹
        branch = tree.add(f"[{style}]{title}[/{style}]")

        # æ·»åŠ å†…å®¹ï¼ˆå¦‚æœæœ‰ä¸”ä¸æ ‡é¢˜ä¸åŒï¼‰
        if node.content and node.content != node.title:
            content_lines = textwrap.wrap(node.content, width=100)
            for line in content_lines:
                branch.add(f"[dim]{line}[/dim]")

        # æ·»åŠ å…ƒæ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        if node.metadata:
            meta_branch = branch.add("[dim]å…ƒæ•°æ®[/dim]")
            for key, value in node.metadata.items():
                meta_branch.add(f"[dim]{key}: {value}[/dim]")

        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in node.children:
            add_node_to_tree(branch, child)

    # åˆ›å»ºä¸»æ ‘
    tree = Tree("ğŸ“„ æ–‡æ¡£ç»“æ„", style="bold blue")
    for child in doc_structure.root.children:
        add_node_to_tree(tree, child)

    # æ˜¾ç¤ºæ ‘
    console.print("\n")
    console.print(Panel(tree, border_style="blue"))
    console.print()


def display_comparison(new_models: set[str], removed_models: set[str]):
    """æ˜¾ç¤ºå‹å·å¯¹æ¯”ç»“æœ"""
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    compare_table = Table(
        title="ğŸ”„ å‹å·å¯¹æ¯”",
        title_style="bold cyan",
        show_header=True,
        header_style="bold green",
        border_style="blue",
    )

    # æ·»åŠ åˆ—
    compare_table.add_column("å˜æ›´ç±»å‹", style="cyan")
    compare_table.add_column("æ•°é‡", justify="right", style="green")
    compare_table.add_column("å‹å·åˆ—è¡¨", style="yellow")

    # æ·»åŠ æ–°å¢å‹å·
    if new_models:
        models_text = "\n".join(f"âœ¨ {model}" for model in sorted(new_models))
        compare_table.add_row("â• æ–°å¢", str(len(new_models)), models_text)

    # æ·»åŠ ç§»é™¤å‹å·
    if removed_models:
        models_text = "\n".join(f"âŒ {model}" for model in sorted(removed_models))
        compare_table.add_row("â– ç§»é™¤", str(len(removed_models)), models_text)

    if new_models or removed_models:
        console.print()
        console.print(compare_table)
        console.print()
    else:
        console.print(Panel("[green]âœ… æ²¡æœ‰å‹å·å˜æ›´[/green]", border_style="green"))


@click.group()
def cli():
    """å¤„ç†è½¦è¾†æ•°æ®æ–‡æ¡£çš„å‘½ä»¤è¡Œå·¥å…·"""
    pass


def extract_car_info(doc_path: str, verbose: bool = False) -> List[Dict[str, Any]]:
    """ä»docxæ–‡ä»¶ä¸­æå–è½¦è¾†ä¿¡æ¯"""
    processor = DocProcessor(doc_path)
    return processor.process()


@cli.command()
@click.argument(
    "input_path",
    type=click.Path(exists=True),
)
@click.option(
    "-o",
    "--output",
    type=click.Path(dir_okay=False),
    default="cars_output.csv",
    help="è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„",
)
@click.option("-v", "--verbose", is_flag=True, help="æ˜¾ç¤ºè¯¦ç»†å¤„ç†ä¿¡æ¯")
@click.option("--preview", is_flag=True, help="æ˜¾ç¤ºæ–‡æ¡£å†…å®¹é¢„è§ˆ")
@click.option(
    "--compare",
    type=click.Path(exists=True, dir_okay=False),
    help="ä¸æŒ‡å®šçš„CSVæ–‡ä»¶è¿›è¡Œå¯¹æ¯”",
)
@click.option(
    "--config",
    type=click.Path(exists=True, dir_okay=False),
    help="é…ç½®æ–‡ä»¶è·¯å¾„",
)
def process(
    input_path: str,
    output: str,
    verbose: bool,
    preview: bool,
    compare: str | None,
    config: str | None,
) -> None:
    """å¤„ç†æŒ‡å®šçš„docxæ–‡ä»¶æˆ–ç›®å½•ä¸‹çš„æ‰€æœ‰docxæ–‡ä»¶"""
    try:
        # è®¾ç½®æ—¥å¿—
        setup_logging()
        logger = logging.getLogger(__name__)
        logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡: è¾“å…¥={input_path}, è¾“å‡º={output}")

        # åŠ è½½é…ç½®
        config_data = {}
        if config:
            try:
                config_data = load_config(config)
                logger.info(f"åŠ è½½é…ç½®æ–‡ä»¶: {config}")
            except ConfigurationError as e:
                logger.error(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
                console.print(f"[bold red]åŠ è½½é…ç½®å¤±è´¥: {str(e)}")
                return

        process_files(input_path, output, verbose, preview, compare, config_data)

    except Exception as e:
        logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
        console.print(f"[bold red]å¤„ç†ä»»åŠ¡å¤±è´¥: {str(e)}")


def get_memory_usage() -> str:
    """è·å–å½“å‰è¿›ç¨‹çš„å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    process = psutil.Process(os.getpid())
    memory_info = process.memory_info()
    return f"{memory_info.rss / 1024 / 1024:.1f}MB"


def process_files(
    input_path: str,
    output: str,
    verbose: bool = False,
    preview: bool = False,
    compare: str | None = None,
    config: dict = None,
) -> None:
    """å¤„ç†æŒ‡å®šçš„docxæ–‡ä»¶æˆ–ç›®å½•ä¸‹çš„æ‰€æœ‰docxæ–‡ä»¶çš„æ ¸å¿ƒé€»è¾‘"""
    logger = logging.getLogger(__name__)

    try:
        input_path_obj = Path(input_path)
        if input_path_obj.is_file():
            if input_path_obj.suffix.lower() != ".docx":
                raise ValueError("æŒ‡å®šçš„æ–‡ä»¶ä¸æ˜¯docxæ–‡ä»¶")
            doc_files = [input_path_obj]
        else:
            doc_files = list(input_path_obj.glob("*.docx"))

        if not doc_files:
            raise ValueError("æœªæ‰¾åˆ°.docxæ–‡ä»¶")

        if preview:
            for doc_file in doc_files:
                print_docx_content(str(doc_file))

        # ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†æ–‡æ¡£
        num_processes = min(mp.cpu_count(), len(doc_files))
        logger.info(f"ä½¿ç”¨ {num_processes} ä¸ªè¿›ç¨‹å¤„ç† {len(doc_files)} ä¸ªæ–‡ä»¶")

        with mp.Pool(num_processes) as pool:
            with Progress(
                "[progress.description]{task.description}",
                SpinnerColumn(),
                BarColumn(bar_width=None),
                "[progress.percentage]{task.percentage:>3.1f}%",
                "â€¢",
                "[bold blue]{task.completed}/{task.total}",
                "â€¢",
                TimeRemainingColumn(),
                "â€¢",
                TimeElapsedColumn(),
                console=console,
                transient=True,
            ) as progress:
                main_task = progress.add_task(
                    f"[bold cyan]ğŸ”„ å¤„ç†æ–‡ä»¶", total=len(doc_files)
                )

                # ä½¿ç”¨partialå›ºå®šå‚æ•°
                process_func = partial(process_doc, verbose=verbose, config=config)

                # ä½¿ç”¨imapå¤„ç†ç»“æœ
                all_cars_data = []
                error_files = []

                for doc_file, cars in zip(
                    doc_files, pool.imap(process_func, [str(f) for f in doc_files])
                ):
                    if cars:
                        all_cars_data.extend(cars)
                        logger.info(
                            f"âœ… æ–‡ä»¶ {doc_file} å¤„ç†å®Œæˆï¼Œæå–åˆ° {len(cars)} æ¡è®°å½•"
                        )
                    else:
                        error_files.append(doc_file)
                        logger.error(f"âŒ æ–‡ä»¶ {doc_file} å¤„ç†å¤±è´¥")

                    progress.advance(main_task)

                    # å®šæœŸæ¸…ç†å†…å­˜
                    if len(all_cars_data) > 10000:
                        gc.collect()

        # å¤„ç†ç»“æœ
        if all_cars_data:
            try:
                # ä½¿ç”¨æ›´é«˜æ•ˆçš„DataFrameæ„å»ºæ–¹å¼
                all_cars_df = pd.DataFrame(all_cars_data)

                # ä¼˜åŒ–åˆ—é¡ºåºè®¾ç½®
                base_columns = [
                    "batch",
                    "car_type",
                    "category",
                    "sub_type",
                    "åºå·",
                    "ä¼ä¸šåç§°",
                    "å“ç‰Œ",
                    "å‹å·",
                    "raw_text",
                ]
                all_columns = all_cars_df.columns.tolist()
                final_columns = [col for col in base_columns if col in all_columns] + [
                    col for col in all_columns if col not in base_columns
                ]

                # é‡æ–°æ’åˆ—åˆ—å¹¶ä¿å­˜
                all_cars_df = all_cars_df[final_columns]
                all_cars_df.to_csv(output, index=False, encoding="utf-8-sig")

                logger.info(f"ğŸ’¾ å¤„ç†å®Œæˆï¼Œä¿å­˜ç»“æœåˆ°: {output}")
                logger.info(f"ğŸ“Š æ€»è®°å½•æ•°: {len(all_cars_df)}")

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                display_statistics(
                    len(all_cars_df),
                    len(all_cars_df[all_cars_df["car_type"] == 2]),
                    len(all_cars_df[all_cars_df["car_type"] == 1]),
                    output,
                )

                # å¦‚æœæœ‰å¤„ç†å¤±è´¥çš„æ–‡ä»¶ï¼Œæ˜¾ç¤ºè­¦å‘Š
                if error_files:
                    error_msg = "âŒ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥:\n" + "\n".join(
                        f"  â€¢ {f}" for f in error_files
                    )
                    logger.warning(error_msg)
                    console.print(
                        Panel(
                            f"[bold yellow]{error_msg}[/bold yellow]",
                            title="âš ï¸ è­¦å‘Š",
                            border_style="yellow",
                        )
                    )

                # å¦‚æœéœ€è¦å¯¹æ¯”
                if compare:
                    try:
                        old_df = pd.read_csv(compare, encoding="utf-8-sig")
                        new_models = set(all_cars_df["å‹å·"].unique())
                        old_models = set(old_df["å‹å·"].unique())
                        display_comparison(
                            new_models - old_models, old_models - new_models
                        )
                        logger.info("âœ… å®Œæˆå‹å·å¯¹æ¯”")
                    except Exception as e:
                        error_msg = f"å¯¹æ¯”æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
                        logger.error(error_msg)
                        console.print(
                            Panel(
                                f"[bold red]{error_msg}[/bold red]",
                                title="âŒ é”™è¯¯",
                                border_style="red",
                            )
                        )

            except Exception as e:
                error_msg = f"å¤„ç†ç»“æœæ—¶å‡ºé”™: {str(e)}"
                logger.error(error_msg)
                console.print(
                    Panel(
                        f"[bold red]{error_msg}[/bold red]",
                        title="âŒ é”™è¯¯",
                        border_style="red",
                    )
                )
        else:
            logger.warning("æœªæ‰¾åˆ°ä»»ä½•è½¦è¾†è®°å½•")
            console.print(
                Panel(
                    "[bold yellow]æœªæ‰¾åˆ°ä»»ä½•è½¦è¾†è®°å½•[/bold yellow]",
                    title="âš ï¸ è­¦å‘Š",
                    border_style="yellow",
                )
            )

    except Exception as e:
        error_msg = f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        logger.error(error_msg)
        console.print(
            Panel(
                f"[bold red]{error_msg}[/bold red]", title="âŒ é”™è¯¯", border_style="red"
            )
        )


@lru_cache(maxsize=32)
def load_document(doc_path: str) -> DocxDocument:
    """ç¼“å­˜åŠ è½½çš„æ–‡æ¡£å¯¹è±¡"""
    return Document(doc_path)


def profile_function(func):
    def wrapper(*args, **kwargs):
        profile = cProfile.Profile()
        try:
            return profile.runcall(func, *args, **kwargs)
        finally:
            s = StringIO()
            stats = pstats.Stats(profile, stream=s).sort_stats("cumulative")
            stats.print_stats(20)  # æ˜¾ç¤ºå‰20ä¸ªæœ€è€—æ—¶çš„å‡½æ•°è°ƒç”¨
            console.print(f"\n[bold cyan]æ€§èƒ½åˆ†ææŠ¥å‘Š:[/bold cyan]\n{s.getvalue()}")

    return wrapper


def setup_logging(
    default_path="logging.yaml", default_level=logging.INFO, env_key="LOG_CFG"
):
    """é…ç½®æ—¥å¿—è®°å½•"""
    path = os.getenv(env_key, default_path)
    if os.path.exists(path):
        with open(path, "rt") as f:
            try:
                config = yaml.safe_load(f.read())
                logging.config.dictConfig(config)
            except Exception as e:
                print(f"åŠ è½½æ—¥å¿—é…ç½®å‡ºé”™: {e}")
                setup_default_logging(default_level)
    else:
        setup_default_logging(default_level)


def setup_default_logging(level):
    """è®¾ç½®é»˜è®¤æ—¥å¿—é…ç½®"""
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"doc_processor_{timestamp}.log")

    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding="utf-8"),
            logging.StreamHandler(),
        ],
    )


class ConfigurationError(Exception):
    """é…ç½®é”™è¯¯å¼‚å¸¸"""

    pass


class ProcessingError(Exception):
    """å¤„ç†é”™è¯¯å¼‚å¸¸"""

    pass


class DocumentError(Exception):
    """æ–‡æ¡£é”™è¯¯å¼‚å¸¸"""

    pass


def load_config(config_path: str = "config.yaml") -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        if os.path.exists(config_path):
            with open(config_path, "r", encoding="utf-8") as f:
                config = yaml.safe_load(f)
            return config
        return {}
    except Exception as e:
        raise ConfigurationError(f"åŠ è½½é…ç½®æ–‡ä»¶å‡ºé”™: {str(e)}")


class DocProcessor:
    def __init__(self, doc_path: str, verbose: bool = True, config: dict = None):
        self.doc_path = doc_path
        self.start_time = time.time()
        self.config = config or {}
        self.logger = logging.getLogger(__name__)
        self.doc_structure = DocumentStructure()

        try:
            self._load_document()
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨å¤±è´¥: {str(e)}")
            raise DocumentError(f"æ— æ³•åŠ è½½æ–‡æ¡£ {doc_path}: {str(e)}")

        self.current_category: Optional[str] = None
        self.current_type: Optional[str] = None
        self.batch_number: Optional[str] = None
        self._table_cache: Dict[int, List[Dict[str, Any]]] = {}
        self.cars: List[Dict[str, Any]] = []
        self._processing_times: Dict[str, float] = {}

        # ä»é…ç½®æ–‡ä»¶åŠ è½½è®¾ç½®
        self._chunk_size = self.config.get("chunk_size", 1000)
        self.verbose = verbose
        self._cache_size_limit = self.config.get("cache_size_limit", 50 * 1024 * 1024)
        self._cleanup_interval = self.config.get("cleanup_interval", 300)

        # é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼
        self._batch_pattern = re.compile(r"ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶\d]+)æ‰¹")
        self._whitespace_pattern = re.compile(r"\s+")
        self._chinese_number_pattern = re.compile(r"([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾é›¶]+)")

        self._last_cache_cleanup = time.time()
        self.logger.info(f"åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨: {doc_path}")

        self.current_section: Optional[DocumentNode] = None
        self.current_subsection: Optional[DocumentNode] = None
        self.current_numbered_section: Optional[DocumentNode] = (
            None  # æ–°å¢ï¼šç”¨äºè·Ÿè¸ªå¸¦æ•°å­—ç¼–å·çš„èŠ‚ç‚¹
        )

    def _load_document(self):
        """å®‰å…¨åŠ è½½æ–‡æ¡£ï¼Œå¤„ç†å¤§æ–‡ä»¶"""
        try:
            file_size = os.path.getsize(self.doc_path)
            self.logger.info(
                f"åŠ è½½æ–‡æ¡£ {self.doc_path}, å¤§å°: {file_size/1024/1024:.2f}MB"
            )

            if file_size > 100 * 1024 * 1024:  # 100MB
                self.logger.warning(f"æ–‡æ¡£å¤§å°è¶…è¿‡100MBï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å¤„ç†")
                with tempfile.NamedTemporaryFile(delete=False) as tmp:
                    shutil.copy2(self.doc_path, tmp.name)
                    self.doc = Document(tmp.name)
                    os.unlink(tmp.name)
            else:
                self.doc = Document(self.doc_path)
        except Exception as e:
            self.logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥: {str(e)}")
            raise DocumentError(f"æ— æ³•åŠ è½½æ–‡æ¡£ {self.doc_path}: {str(e)}")

    def _check_and_cleanup_cache(self):
        """æ£€æŸ¥å¹¶æ¸…ç†ç¼“å­˜"""
        current_time = time.time()
        if current_time - self._last_cache_cleanup > self._cleanup_interval:
            cache_size = sum(len(str(v)) for v in self._table_cache.values())
            if cache_size > self._cache_size_limit:
                self._table_cache.clear()
                gc.collect()
            self._last_cache_cleanup = current_time

    def _extract_table_cells_fast(self, table) -> List[List[str]]:
        """ä¼˜åŒ–çš„è¡¨æ ¼æå–æ–¹æ³•"""
        try:
            rows = []
            header_processed = False
            last_company = ""
            last_brand = ""

            # ä½¿ç”¨lxmlçš„xpathç›´æ¥æå–æ–‡æœ¬
            for row in table._tbl.xpath(".//w:tr"):
                cells = []
                for cell in row.xpath(".//w:tc"):
                    # ç›´æ¥è·å–æ‰€æœ‰æ–‡æœ¬èŠ‚ç‚¹
                    text = "".join(t.text for t in cell.xpath(".//w:t"))
                    cells.append(text.strip())

                if not header_processed:
                    processed_headers = self._process_merged_headers(cells)
                    rows.append(processed_headers)
                    header_processed = True
                    continue

                processed_row = self._process_data_row(cells, last_company, last_brand)
                if processed_row:
                    if processed_row[1]:
                        last_company = processed_row[1]
                    if processed_row[2]:
                        last_brand = processed_row[2]
                    rows.append(processed_row)

                # å®šæœŸæ£€æŸ¥ç¼“å­˜
                self._check_and_cleanup_cache()

            return rows
        except Exception as e:
            logging.error(f"è¡¨æ ¼æå–é”™è¯¯: {str(e)}")
            return []

    def _process_merged_headers(self, headers: List[str]) -> List[str]:
        """å¤„ç†åˆå¹¶çš„è¡¨å¤´"""
        processed = []
        i = 0
        while i < len(headers):
            if (
                headers[i] == "å‹å¼"
                and i + 1 < len(headers)
                and headers[i + 1] == "æ¡£ä½æ•°"
            ):
                processed.append("å˜é€Ÿå™¨")
                i += 2
            else:
                processed.append(headers[i])
                i += 1
        return processed

    def _process_data_row(
        self, row: List[str], last_company: str, last_brand: str
    ) -> Optional[List[str]]:
        """å¤„ç†æ•°æ®è¡Œï¼Œå¤„ç†ç©ºå€¼å’Œå»¶ç»­æ€§"""
        # è·³è¿‡å…¨ç©ºè¡Œ
        if not any(cell.strip() for cell in row):
            return None

        # å¤„ç†åˆè®¡è¡Œ
        if any(cell.strip().startswith(("åˆè®¡", "æ€»è®¡")) for cell in row):
            return None

        processed = []
        for i, cell in enumerate(row):
            value = cell.strip()
            if i == 1 and not value:  # ä¼ä¸šåç§°ä¸ºç©º
                processed.append(last_company)
            elif i == 2 and not value:  # å“ç‰Œ/é€šç”¨åç§°ä¸ºç©º
                processed.append(last_brand)
            elif "å‹å¼" in value and "æ¡£ä½æ•°" in value:  # å¤„ç†å˜é€Ÿå™¨ä¿¡æ¯
                parts = value.split()
                processed.append(f"{parts[0]} {parts[1]}")
            else:
                processed.append(value)

        return processed

    def _extract_car_info(
        self, table_index: int, batch_number: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """ä»è¡¨æ ¼ä¸­æå–è½¦è¾†ä¿¡æ¯ï¼Œä½¿ç”¨ä¼˜åŒ–çš„å¤„ç†æ–¹å¼"""
        # æ£€æŸ¥ç¼“å­˜
        if table_index in self._table_cache:
            return self._table_cache[table_index]

        start_time = time.time()
        table_cars: List[Dict[str, Any]] = []
        table = self.doc.tables[table_index]

        if not table or not table.rows:
            return table_cars

        # ä½¿ç”¨å¿«é€Ÿæ–¹æ³•æå–æ‰€æœ‰å•å…ƒæ ¼å†…å®¹
        all_rows = self._extract_table_cells_fast(table)
        if not all_rows:
            return table_cars

        # è·å–å¹¶å¤„ç†è¡¨å¤´
        headers = [clean_text(cell) for cell in all_rows[0] if cell]
        if not headers:
            return table_cars

        # æ˜¾ç¤ºè¡¨æ ¼ç»“æ„ä¿¡æ¯
        if self.verbose:
            console.print(f"\n[cyan]è¡¨æ ¼ {table_index + 1} ç»“æ„ä¿¡æ¯:[/cyan]")
            console.print(f"è¡¨å¤´: {headers}")
            console.print(f"æ€»è¡Œæ•°: {len(all_rows)}")
            if len(all_rows) > 1:
                console.print(f"ç¬¬ä¸€è¡Œæ•°æ®ç¤ºä¾‹: {all_rows[1]}")

        # æ ¹æ®è¡¨å¤´åˆ¤æ–­è¡¨æ ¼ç±»å‹
        table_category, table_type = get_table_type(
            headers, self.current_category, self.current_type
        )

        # é¢„å…ˆåˆ›å»ºåŸºç¡€ä¿¡æ¯
        base_info = {
            "category": table_category,
            "sub_type": table_type,
            "car_type": 2 if table_category == "èŠ‚èƒ½å‹" else 1,
            "batch": batch_number,
        }

        total_rows = len(all_rows) - 1
        if total_rows > 100:
            console.print(f"[dim]å¼€å§‹å¤„ç†å¤§è¡¨æ ¼ï¼Œå…± {total_rows} è¡Œ[/dim]")

        # åˆ†å—å¤„ç†æ•°æ®è¡Œ
        for chunk_start in range(1, len(all_rows), self._chunk_size):
            chunk_end = min(chunk_start + self._chunk_size, len(all_rows))
            chunk_rows = all_rows[chunk_start:chunk_end]

            # æ‰¹é‡å¤„ç†å½“å‰å—çš„æ•°æ®è¡Œ
            for row_idx, cells in enumerate(chunk_rows, chunk_start):
                # è·³è¿‡ç©ºè¡Œ
                if not any(str(cell).strip() for cell in cells):
                    continue

                # è®°å½•åˆ—æ•°ä¸åŒ¹é…çš„æƒ…å†µï¼Œä½†ä»ç„¶å¤„ç†æ•°æ®
                if len(cells) != len(headers):
                    if self.verbose:
                        console.print(
                            f"[yellow]è¡¨æ ¼ {table_index + 1} ç¬¬ {row_idx} è¡Œåˆ—æ•°ä¸åŒ¹é…: "
                            f"é¢„æœŸ {len(headers)} åˆ—ï¼Œå®é™… {len(cells)} åˆ—[/yellow]"
                        )
                        console.print(f"è¡Œå†…å®¹: {cells}")
                    # è°ƒæ•´å•å…ƒæ ¼æ•°é‡ä»¥åŒ¹é…è¡¨å¤´
                    if len(cells) > len(headers):
                        cells = cells[: len(headers)]
                    else:
                        cells.extend([""] * (len(headers) - len(cells)))

                # åˆ›å»ºæ–°çš„å­—å…¸ï¼Œé¿å…å¼•ç”¨åŒä¸€ä¸ªå¯¹è±¡
                car_info = base_info.copy()
                car_info["raw_text"] = " | ".join(str(cell) for cell in cells)

                # ä½¿ç”¨zipä¼˜åŒ–å­—æ®µæ˜ å°„ï¼ŒåŒæ—¶æ¸…ç†æ–‡æœ¬
                car_info.update(
                    {
                        header: clean_text(str(value))
                        for header, value in zip(headers, cells)
                    }
                )

                # å¤„ç†è½¦è¾†ä¿¡æ¯
                car_info = process_car_info(car_info, batch_number)
                table_cars.append(car_info)

            if total_rows > 100:
                progress = (chunk_end - 1) / total_rows * 100
                console.print(
                    f"[dim]å¤„ç†è¿›åº¦: {progress:.1f}% ({chunk_end-1}/{total_rows})[/dim]"
                )

            # ä¸»åŠ¨è§¦å‘åƒåœ¾å›æ”¶
            if len(table_cars) > 5000:
                gc.collect()

        # ç¼“å­˜ç»“æœ
        self._table_cache[table_index] = table_cars

        # è®°å½•å¤„ç†æ—¶é—´å’Œç»Ÿè®¡ä¿¡æ¯
        elapsed = time.time() - start_time
        if total_rows > 100 or len(table_cars) > 0:
            console.print(
                f"[dim]è¡¨æ ¼ {table_index + 1} å¤„ç†äº† {total_rows} è¡Œï¼Œ"
                f"æ•°æ® {len(table_cars)} è¡Œï¼Œè€—æ—¶: {elapsed:.2f}ç§’[/dim]"
            )

        return table_cars

    def _log_time(self, operation: str) -> None:
        """è®°å½•æ“ä½œè€—æ—¶"""
        current_time = time.time()
        elapsed = current_time - self.start_time
        self._processing_times[operation] = elapsed
        if operation != "init":
            console.print(f"[dim]{operation} è€—æ—¶: {elapsed:.2f}ç§’[/dim]")
        self.start_time = current_time

    @profile_function
    def process(self) -> List[Dict[str, Any]]:
        """å¤„ç†æ–‡æ¡£å¹¶è¿”å›æ‰€æœ‰è½¦è¾†ä¿¡æ¯"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†æ–‡æ¡£: {self.doc_path}")
            self._log_time("init")

            table_count = 0
            row_count = 0
            error_count = 0

            # éå†æ–‡æ¡£ä¸­çš„æ‰€æœ‰å…ƒç´ 
            for element in self.doc.element.body:
                try:
                    # å¤„ç†æ®µè½
                    if element.tag.endswith("p"):
                        text = element.text.strip()
                        if not text:
                            continue

                        # æå–æ‰¹æ¬¡å·
                        if not self.batch_number:
                            self.batch_number = extract_batch_number(text)
                            if self.batch_number:
                                self.doc_structure.set_batch_number(self.batch_number)
                                self.logger.info(f"æå–åˆ°æ‰¹æ¬¡å·: {self.batch_number}")
                                self.doc_structure.add_node(
                                    f"ç¬¬{self.batch_number}æ‰¹", "batch", level=0
                                )

                        # æ›´æ–°åˆ†ç±»ä¿¡æ¯
                        if "ä¸€ã€èŠ‚èƒ½å‹æ±½è½¦" in text:
                            self.current_category = "èŠ‚èƒ½å‹"
                            self.current_section = self.doc_structure.add_node(
                                "èŠ‚èƒ½å‹æ±½è½¦", "section", content=text
                            )
                            self.current_subsection = None
                            self.current_numbered_section = None
                            self.logger.debug(f"æ›´æ–°åˆ†ç±»: {self.current_category}")
                        elif "äºŒã€æ–°èƒ½æºæ±½è½¦" in text:
                            self.current_category = "æ–°èƒ½æº"
                            self.current_section = self.doc_structure.add_node(
                                "æ–°èƒ½æºæ±½è½¦", "section", content=text
                            )
                            self.current_subsection = None
                            self.current_numbered_section = None
                            self.logger.debug(f"æ›´æ–°åˆ†ç±»: {self.current_category}")
                        elif text.startswith("ï¼ˆ") and "ï¼‰" in text:
                            self.current_subsection = self.doc_structure.add_node(
                                text.strip(),
                                "subsection",
                                content=text,
                                parent_node=self.current_section,
                            )
                            self.current_numbered_section = None
                            self.logger.debug(f"æ›´æ–°ç±»å‹: {text}")
                        # å¤„ç†å¸¦æ•°å­—ç¼–å·çš„èŠ‚ç‚¹
                        elif text.startswith(("1.", "2.", "3.", "4.", "5.")):
                            self.current_numbered_section = self.doc_structure.add_node(
                                text.strip(),
                                "numbered_section",
                                content=text,
                                parent_node=self.current_subsection
                                or self.current_section,
                            )
                            self.logger.debug(f"æ›´æ–°ç¼–å·èŠ‚ç‚¹: {text}")
                        # å¤„ç†å¸¦æ‹¬å·æ•°å­—ç¼–å·çš„å­èŠ‚ç‚¹
                        elif text.startswith("ï¼ˆ") and any(
                            num in text for num in "123456789"
                        ):
                            if self.current_numbered_section:
                                self.doc_structure.add_node(
                                    text.strip(),
                                    "numbered_subsection",
                                    content=text,
                                    parent_node=self.current_numbered_section,
                                )
                            else:
                                self.doc_structure.add_node(
                                    text.strip(),
                                    "numbered_subsection",
                                    content=text,
                                    parent_node=self.current_subsection
                                    or self.current_section,
                                )
                            self.logger.debug(f"æ›´æ–°ç¼–å·å­èŠ‚ç‚¹: {text}")
                        elif "å‹˜è¯¯" in text or "è¯´æ˜" in text:
                            self.doc_structure.add_node(
                                text[:20] + "...",
                                "note",
                                content=text,
                                parent_node=self.current_section,
                            )
                        elif "æ›´æ­£" in text or "ä¿®æ”¹" in text:
                            self.doc_structure.add_node(
                                text[:20] + "...",
                                "correction",
                                content=text,
                                parent_node=self.current_section,
                            )
                        else:
                            self.doc_structure.add_node(
                                text[:20] + "...",
                                "text",
                                content=text,
                                parent_node=self.current_section,
                            )

                    # å¤„ç†è¡¨æ ¼
                    elif element.tag.endswith("tbl"):
                        table_count += 1
                        for i, table in enumerate(self.doc.tables):
                            if table._element is element:
                                if table.rows:
                                    row_count += len(table.rows)
                                try:
                                    table_cars = self._extract_car_info(
                                        i, self.batch_number
                                    )
                                    self.cars.extend(table_cars)

                                    # æ·»åŠ è¡¨æ ¼èŠ‚ç‚¹åˆ°æ­£ç¡®çš„çˆ¶èŠ‚ç‚¹
                                    parent_node = (
                                        self.current_numbered_section
                                        or self.current_subsection
                                        or self.current_section
                                    )
                                    self.doc_structure.add_node(
                                        f"è¡¨æ ¼ {i+1}",
                                        "table",
                                        metadata={
                                            "rows": len(table.rows),
                                            "columns": len(table.rows[0].cells)
                                            if table.rows
                                            else 0,
                                            "records": len(table_cars),
                                        },
                                        parent_node=parent_node,
                                    )

                                    self.logger.info(
                                        f"å¤„ç†è¡¨æ ¼ {i+1}, æå–åˆ° {len(table_cars)} æ¡è®°å½•"
                                    )
                                except Exception as e:
                                    error_count += 1
                                    self.logger.error(f"å¤„ç†è¡¨æ ¼ {i+1} å‡ºé”™: {str(e)}")
                                break
                except Exception as e:
                    error_count += 1
                    self.logger.error(f"å¤„ç†å…ƒç´ å‡ºé”™: {str(e)}")
                    continue

            self._log_time("process")
            self.logger.info(
                f"æ–‡æ¡£å¤„ç†å®Œæˆ: {table_count} ä¸ªè¡¨æ ¼, {row_count} è¡Œ, "
                f"{len(self.cars)} æ¡è®°å½•, {error_count} ä¸ªé”™è¯¯"
            )

            # æ˜¾ç¤ºæ–‡æ¡£ç»“æ„
            if self.verbose:
                display_doc_content(self.doc_structure)

            return self.cars

        except Exception as e:
            self.logger.error(f"å¤„ç†æ–‡æ¡£å¤±è´¥: {str(e)}")
            raise ProcessingError(f"å¤„ç†æ–‡æ¡£ {self.doc_path} å¤±è´¥: {str(e)}")


def process_doc(
    doc_path: str, verbose: bool = False, config: dict = None
) -> List[Dict[str, Any]]:
    """å•ä¸ªæ–‡æ¡£å¤„ç†å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹"""
    try:
        processor = DocProcessor(doc_path, verbose, config)
        return processor.process()
    except Exception as e:
        logging.error(f"å¤„ç†æ–‡æ¡£ {doc_path} å¤±è´¥: {str(e)}")
        return []


if __name__ == "__main__":
    cli()
